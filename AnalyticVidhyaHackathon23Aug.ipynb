{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_sample = pd.read_csv('sample_submission_UVKGLZE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                      0\n",
       "TITLE                   0\n",
       "ABSTRACT                0\n",
       "Computer Science        0\n",
       "Physics                 0\n",
       "Mathematics             0\n",
       "Statistics              0\n",
       "Quantitative Biology    0\n",
       "Quantitative Finance    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(['ID'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance']\n",
    "X = df_train.loc[:,['TITLE','ABSTRACT']]\n",
    "y = df_train.loc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=55, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.reset_index(drop=True,inplace=True)\n",
    "X_test.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array(y_train)\n",
    "y2 = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\envs\\Keras366\\lib\\site-packages\\pandas\\core\\frame.py:4172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  method=method,\n"
     ]
    }
   ],
   "source": [
    "#Removing Punctuations\n",
    "X_train.replace('[^a-zA-Z]',' ', regex=True, inplace=True)\n",
    "X_test.replace('[^a-zA-Z]',' ', regex=True, inplace=True)\n",
    "\n",
    "df_test.replace('[^a-zA-Z]',' ', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\envs\\Keras366\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\HP\\Anaconda3\\envs\\Keras366\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Converting to lower case characters\n",
    "\n",
    "for index in X_train.columns:\n",
    "  X_train[index] = X_train[index].str.lower()\n",
    "\n",
    "for index in X_test.columns:\n",
    "  X_test[index] = X_test[index].str.lower()\n",
    "\n",
    "for index in df_test.columns:\n",
    "  df_test[index] = df_test[index].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\envs\\Keras366\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\HP\\Anaconda3\\envs\\Keras366\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train['combined'] = X_train['TITLE']+' '+X_train['ABSTRACT']\n",
    "X_test['combined'] = X_test['TITLE']+' '+X_test['ABSTRACT']\n",
    "\n",
    "df_test['combined'] = df_test['TITLE']+' '+df_test['ABSTRACT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\envs\\Keras366\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\HP\\Anaconda3\\envs\\Keras366\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Removing one letter words\n",
    "\n",
    "X_train['combined'] = X_train['combined'].str.replace(r'\\b\\w\\b', '').str.replace(r'\\s+', ' ')\n",
    "X_test['combined'] = X_test['combined'].str.replace(r'\\b\\w\\b', '').str.replace(r'\\s+', ' ')\n",
    "\n",
    "df_test['combined'] = df_test['combined'].str.replace(r'\\b\\w\\b', '').str.replace(r'\\s+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing multiple blank spaces\n",
    "\n",
    "X_train = X_train.replace('\\s+', ' ', regex=True)\n",
    "X_test = X_test.replace('\\s+', ' ', regex=True)\n",
    "\n",
    "df_test = df_test.replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "len(stop_words)\n",
    "\n",
    "\n",
    "\n",
    "X_train['combined'] = X_train['combined'].apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))\n",
    "X_test['combined'] = X_test['combined'].apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))\n",
    "\n",
    "df_test['combined'] = df_test['combined'].apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['TITLE','ABSTRACT'],axis=1)\n",
    "X_test = X_test.drop(['TITLE','ABSTRACT'],axis=1)\n",
    "\n",
    "df_test = df_test.drop(['TITLE','ABSTRACT'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lines = []\n",
    "for row in range(0,X_train.shape[0]):\n",
    "  train_lines.append(' '.join(str(x) for x in X_train.iloc[row,:]))\n",
    "\n",
    "test_lines = []\n",
    "for row in range(0,X_test.shape[0]):\n",
    "  test_lines.append(' '.join(str(x) for x in X_test.iloc[row,:]))\n",
    "\n",
    "predtest_lines = []\n",
    "for row in range(0,df_test.shape[0]):\n",
    "  predtest_lines.append(' '.join(str(x) for x in df_test.iloc[row,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.replace('[^a-zA-Z]',' ', regex=True, inplace=True)\n",
    "\n",
    "for index in X.columns:\n",
    "  X[index] = X[index].str.lower()\n",
    "\n",
    "X['ABSTRACT'] = X['ABSTRACT'].str.replace(r'\\b\\w\\b', '').str.replace(r'\\s+', ' ')\n",
    "\n",
    "#X['combined'] = X['combined'].apply(lambda x: decontracted(x))\n",
    "\n",
    "X = X.replace('\\s+', ' ', regex=True)\n",
    "\n",
    "X['ABSTRACT'] = X['ABSTRACT'].apply(lambda x: ' '.join(term for term in x.split() if term not in stop_words))\n",
    "\n",
    "#X['combined'] = X['combined'].apply(get_adjectives)\n",
    "\n",
    "X['combined'] = X['TITLE']+' '+X['ABSTRACT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(['TITLE','ABSTRACT'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lines = []\n",
    "for row in range(0,X.shape[0]):\n",
    "  X_lines.append(' '.join(str(x) for x in X.iloc[row,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "countvector = CountVectorizer(ngram_range=(1,2), stop_words='english')\n",
    "X_train_cv = countvector.fit_transform(train_lines)\n",
    "X_test_cv = countvector.transform(test_lines)\n",
    "\n",
    "test_cv = countvector.transform(predtest_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "\n",
    "tfidfvector = TfidfTransformer()\n",
    "X_train_tf = tfidfvector.fit_transform(X_train_cv)\n",
    "X_test_tf = tfidfvector.fit_transform(X_test_cv)\n",
    "\n",
    "test_tf = tfidfvector.fit_transform(test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cv = countvector.transform(X_lines)\n",
    "X_tf = tfidfvector.fit_transform(X_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "model = LinearSVC(class_weight='balanced')\n",
    "models = MultiOutputClassifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=LinearSVC(class_weight='balanced'))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.fit(X_tf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = models.predict(X_test_tf)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       857\n",
      "           1       0.99      1.00      0.99       596\n",
      "           2       0.98      1.00      0.99       568\n",
      "           3       0.92      1.00      0.96       504\n",
      "           4       0.90      1.00      0.95        54\n",
      "           5       1.00      1.00      1.00        27\n",
      "\n",
      "   micro avg       0.96      1.00      0.98      2606\n",
      "   macro avg       0.96      1.00      0.98      2606\n",
      "weighted avg       0.96      1.00      0.98      2606\n",
      " samples avg       0.98      1.00      0.98      2606\n",
      "\n",
      "0.949952335557674\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "#print(confusion_matrix(y2,preds))\n",
    "print(classification_report(y2,preds))\n",
    "print(accuracy_score(y2,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predssv = models.predict(test_tf)\n",
    "predssv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submit = pd.DataFrame({'ID': df_sample.ID, 'Computer Science': predssv[:,0],'Physics':predssv[:,1],'Mathematics':predssv[:,2],'Statistics':predssv[:,3],'Quantitative Biology':predssv[:,4],'Quantitative Finance':predssv[:,5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('submissionLinearSVC.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
